{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ec5c232",
   "metadata": {},
   "source": [
    "# Mushroom Classifer Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f209222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ffd2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = [x for x in os.listdir('MUSHROOM_images/') if x.endswith('.jpg')]\n",
    "categories = set([x[:-8] for x in all_images])\n",
    "category2images = {category : [] for category in categories}\n",
    "for img in all_images:\n",
    "    category2images[img[:-8]].append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10aa0bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat_01b.jpg',\n",
       " 'cat_04s.jpg',\n",
       " 'dog_01b.jpg',\n",
       " 'dog_06s.jpg',\n",
       " 'mango_01b.jpg',\n",
       " 'mango_03s.jpg']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee3e4228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat', 'dog', 'mango'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "407fcb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27402cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: diffusers[torch] in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.35.2)\n",
      "Requirement already satisfied: importlib_metadata in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers[torch]) (8.7.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers[torch]) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.34.0 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers[torch]) (0.36.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers[torch]) (2.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers[torch]) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers[torch]) (2.32.5)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers[torch]) (0.7.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers[torch]) (11.0.0)\n",
      "Requirement already satisfied: torch>=1.4 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers[torch]) (2.9.1)\n",
      "Requirement already satisfied: accelerate>=0.31.0 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers[torch]) (1.12.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from accelerate>=0.31.0->diffusers[torch]) (24.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from accelerate>=0.31.0->diffusers[torch]) (6.1.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from accelerate>=0.31.0->diffusers[torch]) (6.0.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.34.0->diffusers[torch]) (2025.12.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.34.0->diffusers[torch]) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.34.0->diffusers[torch]) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.4->diffusers[torch]) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.4->diffusers[torch]) (3.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.4->diffusers[torch]) (3.1.6)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from importlib_metadata->diffusers[torch]) (3.23.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->diffusers[torch]) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->diffusers[torch]) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->diffusers[torch]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->diffusers[torch]) (2025.11.12)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy>=1.13.3->torch>=1.4->diffusers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.34.0->diffusers[torch]) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch>=1.4->diffusers[torch]) (3.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\Athena\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.57.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2025.11.12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\Athena\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade diffusers[torch]\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "abf32d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableUnCLIPImg2ImgPipeline\n",
    "from transformers import CLIPTextModelWithProjection, CLIPTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c837708",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21762ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 9/9 [00:13<00:00,  1.49s/it]\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n"
     ]
    }
   ],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# 1.  Load unCLIP – vision side only (projection_dim = 1024)   ─\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "pipe = StableUnCLIPImg2ImgPipeline.from_pretrained(\n",
    "    \"sd2-community/stable-diffusion-2-1-unclip\",\n",
    "    torch_dtype=torch.float16,\n",
    ").to(device)\n",
    "\n",
    "vision_encoder = pipe.image_encoder                       # keep as-is (1024-d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed3a2aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# 2.  Swap in an OpenCLIP ViT-H/14 text branch (also 1024-d)  ─\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "openclip_repo = \"laion/CLIP-ViT-H-14-laion2B-s32B-b79K\"     # projection_dim = 1024 :contentReference[oaicite:0]{index=0}\n",
    "tokenizer = CLIPTokenizer.from_pretrained(openclip_repo)\n",
    "text_encoder = CLIPTextModelWithProjection.from_pretrained(\n",
    "    openclip_repo,\n",
    "    torch_dtype=torch.float16\n",
    ").to(device)\n",
    "\n",
    "# optional: stuff them into the pipe so `pipe.tokenizer` etc. work\n",
    "pipe.tokenizer, pipe.text_encoder = tokenizer, text_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d265fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# 3. Helpers                                              \n",
    "# ──────────────────────────────────────────────────────────────\n",
    "def embed_images(paths, batch_size=8):\n",
    "    \"\"\"Return (N,1024) image embeddings\"\"\"\n",
    "    out, fe, enc = [], pipe.feature_extractor, pipe.image_encoder\n",
    "    for i in range(0, len(paths), batch_size):\n",
    "        imgs = [Image.open(p).convert(\"RGB\") for p in paths[i:i + batch_size]]\n",
    "        px   = fe(imgs, return_tensors=\"pt\").pixel_values.to(enc.device, enc.dtype)\n",
    "        with torch.no_grad():\n",
    "            v = enc(px)[0]                              # (B,1024)\n",
    "        out.append(v)\n",
    "    return torch.cat(out)  # (N,1024)\n",
    "\n",
    "def embed_texts(prompts, batch_size=64):\n",
    "    \"\"\"Return (N,1024) text embeddings\"\"\"\n",
    "    vecs = []\n",
    "    for i in range(0, len(prompts), batch_size):\n",
    "        toks = tokenizer(prompts[i:i + batch_size],\n",
    "                         padding=True, truncation=True, max_length=77,\n",
    "                         return_tensors=\"pt\").to(text_encoder.device)\n",
    "        with torch.no_grad():\n",
    "            t = text_encoder(**toks).text_embeds        # (B,1024)\n",
    "        vecs.append(t)\n",
    "    return torch.cat(vecs)  # (N,1024)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25495740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test1.jpg', 'test2.jpg', 'test3.jpg', 'test4.jpg']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('THINGS_images/test_images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbbf051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(pipe, image, label):\n",
    "    '''\n",
    "    This function classifies an image using CLIP\n",
    "    - image: is the image path\n",
    "    - pipe: is the image encoder + text encoder\n",
    "    - label: takes in a list of possible labels\n",
    "    '''\n",
    "\n",
    "    # labels\n",
    "    labels = label\n",
    "\n",
    "    # CLIP image and text\n",
    "    img = embed_images([image])\n",
    "    txt = embed_texts(labels)\n",
    "\n",
    "    #normalize for cosine similarity\n",
    "    img = torch.nn.functional.normalize(img, dim=-1)\n",
    "    txt = torch.nn.functional.normalize(txt, dim=-1)\n",
    "\n",
    "    #compute cosine similarities \n",
    "    sim = (img @ txt.T).squeeze(0)\n",
    "\n",
    "    # pick label\n",
    "    best = sim.argmax().item()\n",
    "    best_label = labels[best]\n",
    "    best_score = sim[best].item()\n",
    "\n",
    "    return best_label\n",
    "    #, best_score, sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91a41708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mango\n"
     ]
    }
   ],
   "source": [
    "print(classify(pipe, \"THINGS_images/mango_01b.jpg\", [\"cat\", \"mango\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d8da6f",
   "metadata": {},
   "source": [
    "# Embed Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de32c182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the images \n",
    "# img_embeddings = embed_images(image_path) --> maybe loop through later\n",
    "# optional: normalize embeddings to unit vectos for cosine similarity here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5674011e",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198ef0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do PCA \n",
    "# reduce dimensions to make clustering and visualization easier\n",
    "\n",
    "# note: this imports PCA, rather than us manually implementing it\n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "pca = PCA(n_components=50)\n",
    "X_reduced = pca.fit_transform(img_embeddings.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b39a81",
   "metadata": {},
   "source": [
    "# k-means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9418eb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: we can use regular image embeddings [img_embeddings] \n",
    "# however, we can use the PCA reduced [X_reduced]\n",
    "\n",
    "# note: this imports KMeans, but we can manually do it as well\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 2 clusters //can change\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "kmeans.fit(X_reduced)\n",
    "\n",
    "# assign each image to a cluster\n",
    "clusterlabels = kmeans.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f2e340",
   "metadata": {},
   "source": [
    "# Classify tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5658d296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifying using text descriptions \n",
    "description_labels = [\"small brown mushroom with gills\", \"red mushroom with white spots\"]\n",
    "predictions_desc = [classify(pipe, img, labels=description_labels) for img in all_images]\n",
    "\n",
    "# classifying using mushroom names \n",
    "species_labels = [\"placeholder\"]\n",
    "predictions_names = [classify(pipe, img, labels=species_labels) for img in all_images]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
