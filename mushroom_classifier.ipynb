{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ec5c232",
   "metadata": {},
   "source": [
    "# Mushroom Classifer Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f209222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95ffd2f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'MUSHROOM_images/'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m all_images = [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mMUSHROOM_images/\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m x.endswith(\u001b[33m'\u001b[39m\u001b[33m.jpg\u001b[39m\u001b[33m'\u001b[39m)]\n\u001b[32m      2\u001b[39m categories = \u001b[38;5;28mset\u001b[39m([x[:-\u001b[32m8\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m all_images])\n\u001b[32m      3\u001b[39m category2images = {category : [] \u001b[38;5;28;01mfor\u001b[39;00m category \u001b[38;5;129;01min\u001b[39;00m categories}\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] The system cannot find the path specified: 'MUSHROOM_images/'"
     ]
    }
   ],
   "source": [
    "all_images = [x for x in os.listdir('MUSHROOM_images/') if x.endswith('.jpg')]\n",
    "categories = set([x[:-8] for x in all_images])\n",
    "category2images = {category : [] for category in categories}\n",
    "for img in all_images:\n",
    "    category2images[img[:-8]].append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aa0bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat_01b.jpg',\n",
       " 'cat_04s.jpg',\n",
       " 'dog_01b.jpg',\n",
       " 'dog_06s.jpg',\n",
       " 'mango_01b.jpg',\n",
       " 'mango_03s.jpg']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3e4228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat', 'dog', 'mango'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407fcb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27402cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: diffusers[torch] in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.35.2)\n",
      "Requirement already satisfied: importlib_metadata in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers[torch]) (8.7.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers[torch]) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.34.0 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers[torch]) (0.36.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers[torch]) (2.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers[torch]) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers[torch]) (2.32.5)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers[torch]) (0.7.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers[torch]) (11.0.0)\n",
      "Requirement already satisfied: torch>=1.4 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers[torch]) (2.9.1)\n",
      "Requirement already satisfied: accelerate>=0.31.0 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers[torch]) (1.12.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from accelerate>=0.31.0->diffusers[torch]) (24.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from accelerate>=0.31.0->diffusers[torch]) (6.1.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from accelerate>=0.31.0->diffusers[torch]) (6.0.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.34.0->diffusers[torch]) (2025.12.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.34.0->diffusers[torch]) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.34.0->diffusers[torch]) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.4->diffusers[torch]) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.4->diffusers[torch]) (3.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.4->diffusers[torch]) (3.1.6)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from importlib_metadata->diffusers[torch]) (3.23.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->diffusers[torch]) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->diffusers[torch]) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->diffusers[torch]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->diffusers[torch]) (2025.11.12)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy>=1.13.3->torch>=1.4->diffusers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.34.0->diffusers[torch]) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch>=1.4->diffusers[torch]) (3.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\Athena\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.57.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\athena\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2025.11.12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\Athena\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade diffusers[torch]\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf32d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableUnCLIPImg2ImgPipeline\n",
    "from transformers import CLIPTextModelWithProjection, CLIPTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c837708",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21762ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 9/9 [00:13<00:00,  1.49s/it]\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n"
     ]
    }
   ],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# 1.  Load unCLIP – vision side only (projection_dim = 1024)   ─\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "pipe = StableUnCLIPImg2ImgPipeline.from_pretrained(\n",
    "    \"sd2-community/stable-diffusion-2-1-unclip\",\n",
    "    torch_dtype=torch.float16,\n",
    ").to(device)\n",
    "\n",
    "vision_encoder = pipe.image_encoder                       # keep as-is (1024-d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3a2aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# 2.  Swap in an OpenCLIP ViT-H/14 text branch (also 1024-d)  ─\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "openclip_repo = \"laion/CLIP-ViT-H-14-laion2B-s32B-b79K\"     # projection_dim = 1024 :contentReference[oaicite:0]{index=0}\n",
    "tokenizer = CLIPTokenizer.from_pretrained(openclip_repo)\n",
    "text_encoder = CLIPTextModelWithProjection.from_pretrained(\n",
    "    openclip_repo,\n",
    "    torch_dtype=torch.float16\n",
    ").to(device)\n",
    "\n",
    "# optional: stuff them into the pipe so `pipe.tokenizer` etc. work\n",
    "pipe.tokenizer, pipe.text_encoder = tokenizer, text_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d265fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# 3. Helpers                                              \n",
    "# ──────────────────────────────────────────────────────────────\n",
    "def embed_images(paths, batch_size=8):\n",
    "    \"\"\"Return (N,1024) image embeddings\"\"\"\n",
    "    out, fe, enc = [], pipe.feature_extractor, pipe.image_encoder\n",
    "    for i in range(0, len(paths), batch_size):\n",
    "        imgs = [Image.open(p).convert(\"RGB\") for p in paths[i:i + batch_size]]\n",
    "        px   = fe(imgs, return_tensors=\"pt\").pixel_values.to(enc.device, enc.dtype)\n",
    "        with torch.no_grad():\n",
    "            v = enc(px)[0]                              # (B,1024)\n",
    "        out.append(v)\n",
    "    return torch.cat(out)  # (N,1024)\n",
    "\n",
    "def embed_texts(prompts, batch_size=64):\n",
    "    \"\"\"Return (N,1024) text embeddings\"\"\"\n",
    "    vecs = []\n",
    "    for i in range(0, len(prompts), batch_size):\n",
    "        toks = tokenizer(prompts[i:i + batch_size],\n",
    "                         padding=True, truncation=True, max_length=77,\n",
    "                         return_tensors=\"pt\").to(text_encoder.device)\n",
    "        with torch.no_grad():\n",
    "            t = text_encoder(**toks).text_embeds        # (B,1024)\n",
    "        vecs.append(t)\n",
    "    return torch.cat(vecs)  # (N,1024)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25495740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test1.jpg', 'test2.jpg', 'test3.jpg', 'test4.jpg']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('THINGS_images/test_images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbbf051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(pipe, image, label):\n",
    "    '''\n",
    "    This function classifies an image using CLIP\n",
    "    - image: is the image path\n",
    "    - pipe: is the image encoder + text encoder\n",
    "    - label: takes in a list of possible labels\n",
    "    '''\n",
    "\n",
    "    # labels\n",
    "    labels = label\n",
    "\n",
    "    # CLIP image and text\n",
    "    img = embed_images([image])\n",
    "    txt = embed_texts(labels)\n",
    "\n",
    "    #normalize for cosine similarity\n",
    "    img = torch.nn.functional.normalize(img, dim=-1)\n",
    "    txt = torch.nn.functional.normalize(txt, dim=-1)\n",
    "\n",
    "    #compute cosine similarities \n",
    "    sim = (img @ txt.T).squeeze(0)\n",
    "\n",
    "    # pick label\n",
    "    best = sim.argmax().item()\n",
    "    best_label = labels[best]\n",
    "    best_score = sim[best].item()\n",
    "\n",
    "    return best_label\n",
    "    #, best_score, sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a41708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mango\n"
     ]
    }
   ],
   "source": [
    "print(classify(pipe, \"THINGS_images/mango_01b.jpg\", [\"cat\", \"mango\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712faa1b",
   "metadata": {},
   "source": [
    "# PCA (all functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4620f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# embeddings is the numpy array/matrix of the embedded images\n",
    "#n_components is how many principal components we want \n",
    "def run_pca(embeds, n = 2):\n",
    "    pca = PCA(n_components = n)\n",
    "    reduced = pca.fit_transform(embeds)\n",
    "    return reduced, pca\n",
    "\n",
    "#plot sorted eigenvalues to see drop off (how many components actually matter)\n",
    "#make sure to run ^pca with as many prinicipal components as possible before this \n",
    "def plot_eigenvalues(pca):\n",
    "    eigenvalues = pca.explained_variance_\n",
    "\n",
    "    plt.figure(figsize = (8,4))\n",
    "    plt.plot(range(1, len(eigenvalues) + 1), eigenvalues, marker = 'o')\n",
    "    plt.title(\"PCA eigenvalues\")\n",
    "    plt.xlabel(\"Principal Component\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "#requires 2 principal components to make it 2d \n",
    "#that's why it's red_embeds (reduced embeddings) should be size (.., 2)\n",
    "# eg use:::\n",
    "#   pca2, pca_model = run_pca(embeddings, n_components=2)\n",
    "#   plot_pca_2d(pca2, labels=species_names)\n",
    "def plot_pca_2d(red_embeds, labels = None, title = \"PCA Scatter Plot\"):\n",
    "    plt.figure(figsize = (6,6))\n",
    "    if labels is None:\n",
    "        plt.scatter(red_embeds[:, 0], red_embeds[:,1]) #basically plots all points as one color\n",
    "    else:\n",
    "        for lab in np.unique(labels):\n",
    "            idx = [i for i, x in enumerate(labels) if x == lab]\n",
    "            plt.scatter(red_embeds[idx, 0], red_embeds[idx, 1], label=str(lab))\n",
    "        plt.legend()\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b39a81",
   "metadata": {},
   "source": [
    "# K-means (all funtions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9418eb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: we can use regular image embeddings or PCA reduced\n",
    "# note: this imports KMeans, but we can manually do it as well\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def cluster(img_embeds, text_embeds = None, n = 2, rs = 42):\n",
    "    \"\"\"\n",
    "    Params: \n",
    "    img_embeds is the numpy array of image embeddings \n",
    "    text_embeds is the numpy array of text embeddings (can b omitted for just image kmeans)\n",
    "    n is number of clusters (how many diff mushrooms we put in)\n",
    "    rs is reproducibility ig but idk what that means \n",
    "\n",
    "    returns cluster labels( as an array of cluster indices)\n",
    "    and kmeans \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if text_embeds is not None:\n",
    "        X = np.concatenate([img_embeds, text_embeds], axis = 1)\n",
    "    else:\n",
    "        X = img_embeds\n",
    "\n",
    "    kmeans = KMeans(n_clusters = n, random_state = rs)\n",
    "    kmeans.fit(X)\n",
    "\n",
    "    cluster_labels = kmeans.labels_\n",
    "    return cluster_labels, kmeans\n",
    "\n",
    "#ok to plot and see the k-means, run plot_pca_2d with a 2d pca and labels=clusters, where clusters is the cluster labels we get from k-means\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f2e340",
   "metadata": {},
   "source": [
    "# Classify tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5658d296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifying using text descriptions \n",
    "description_labels = [\"small brown mushroom with gills\", \"red mushroom with white spots\"]\n",
    "predictions_desc = [classify(pipe, img, labels=description_labels) for img in all_images]\n",
    "\n",
    "# classifying using mushroom names \n",
    "species_labels = [\"placeholder\"]\n",
    "predictions_names = [classify(pipe, img, labels=species_labels) for img in all_images]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
