{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0343c083",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Melissa Wang\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading pipeline components...:   0%|          | 0/9 [00:00<?, ?it/s]`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading pipeline components...: 100%|██████████| 9/9 [00:11<00:00,  1.30s/it]\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "from mushroom import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600121b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = \"mushrooms\"\n",
    "batch_size = 8\n",
    "\n",
    "embeds_path = \"embeds_all.npy\"\n",
    "gt_labels_path = \"ground_truth_labels.npy\"\n",
    "pred_labels_path = \"predicted_labels.npy\"\n",
    "species_names_path = \"species_names.npy\"\n",
    "image_paths_path = \"image_paths.npy\"\n",
    "\n",
    "if all(os.path.exists(p) for p in [embeds_path, gt_labels_path, pred_labels_path, species_names_path, image_paths_path]):\n",
    "    all_embeds = np.load(embeds_path)\n",
    "    ground_truth_labels = np.load(gt_labels_path)\n",
    "    pred_labels = np.load(pred_labels_path)\n",
    "    species_names = np.load(species_names_path, allow_pickle=True)\n",
    "    image_paths = np.load(image_paths_path, allow_pickle=True)\n",
    "    print(\"All data loaded from saved files.\")\n",
    "else:\n",
    "    all_embeds = []\n",
    "    ground_truth_labels = []\n",
    "    image_paths = []\n",
    "\n",
    "    for species in os.listdir(root_folder):\n",
    "            species_folder = os.path.join(root_folder, species)\n",
    "            if os.path.isdir(species_folder):\n",
    "                files = sorted(f for f in os.listdir(species_folder) if f.lower().endswith(\".png\"))\n",
    "                paths = [os.path.join(species_folder, f) for f in files]\n",
    "                image_paths.extend(paths)\n",
    "                ground_truth_labels.extend([species] * len(files))\n",
    "                embeds = embed_whole_folder(species_folder, bs=batch_size)  # your embedding function\n",
    "                all_embeds.append(embeds)\n",
    "\n",
    "    all_embeds = np.vstack(all_embeds)\n",
    "    all_embeds = normalize_embeds(all_embeds)\n",
    "    ground_truth_labels = np.array(ground_truth_labels)\n",
    "    species_names = list(np.unique(ground_truth_labels))\n",
    "    pred_labels = classify_images(pipe, image_paths, species_names)\n",
    "\n",
    "    np.save(embeds_path, all_embeds)\n",
    "    np.save(gt_labels_path, ground_truth_labels)\n",
    "    np.save(pred_labels_path, pred_labels)\n",
    "    np.save(species_names_path, species_names)\n",
    "    np.save(image_paths_path, image_paths)\n",
    "\n",
    "    print(\"All embeddings, labels, and predictions computed and saved.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fbdeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding all images once and saving \n",
    "root_folder = \"mushrooms\"        # main folder containing species subfolders\n",
    "batch_size = 8                   # batch size for embedding\n",
    "save_path = \"embeds_all.npy\"\n",
    "\n",
    "all_embeds = []\n",
    "\n",
    "for species in os.listdir(root_folder):\n",
    "    species_folder = os.path.join(root_folder, species)\n",
    "    if os.path.isdir(species_folder):\n",
    "        embeds = embed_whole_folder(species_folder, bs=batch_size)\n",
    "        all_embeds.append(embeds)\n",
    "\n",
    "all_embeds = np.vstack(all_embeds)\n",
    "all_embeds = normalize_embeds(all_embeds)\n",
    "np.save(save_path, all_embeds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f2e89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 predicted labels: [np.str_('fly_agaric'), np.str_('fly_agaric'), np.str_('fly_agaric'), np.str_('beefsteak_fungus'), np.str_('fly_agaric'), np.str_('fly_agaric'), np.str_('fly_agaric'), np.str_('fly_agaric'), np.str_('fly_agaric'), np.str_('fly_agaric')]\n"
     ]
    }
   ],
   "source": [
    "root_folder = \"mushrooms\"        # main folder containing species subfolders\n",
    "batch_size = 8         \n",
    "ground_truth_labels = []\n",
    "image_paths = []\n",
    "for species in os.listdir(root_folder):\n",
    "    species_folder = os.path.join(root_folder, species)\n",
    "    if os.path.isdir(species_folder):\n",
    "        files = [f for f in sorted(os.listdir(species_folder)) if f.lower().endswith(\".png\")]\n",
    "        img_count = len(files)\n",
    "        image_paths.extend([os.path.join(species_folder, f) for f in files])    \n",
    "        ground_truth_labels.extend([species] * img_count)\n",
    "\n",
    "ground_truth_labels = np.array(ground_truth_labels)\n",
    "\n",
    "species_names = list(np.unique(ground_truth_labels))\n",
    "pred_labels = classify_images(pipe, image_paths, species_names)\n",
    "\n",
    "np.save(\"predicted_labels.npy\", pred_labels)\n",
    "np.save(\"ground_truth_labels.npy\", ground_truth_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "665097b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'species_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m num_clusters = \u001b[38;5;28mlen\u001b[39m(\u001b[43mspecies_names\u001b[49m)\n\u001b[32m      3\u001b[39m kmeans_labels, kmeans_model = cluster(all_embeds, n=num_clusters)\n\u001b[32m      4\u001b[39m gmm_labels, gmm_probs, gmm_model = cluster_gmm(all_embeds, k=num_clusters)\n",
      "\u001b[31mNameError\u001b[39m: name 'species_names' is not defined"
     ]
    }
   ],
   "source": [
    "num_clusters = len(species_names)\n",
    "\n",
    "kmeans_labels, kmeans_model = cluster(all_embeds, n=num_clusters)\n",
    "gmm_labels, gmm_probs, gmm_model = cluster_gmm(all_embeds, k=num_clusters)\n",
    "agg_labels, agg_model = cluster_agglomerative(all_embeds, k=num_clusters)\n",
    "spec_labels, spec_model = cluster_spectral(all_embeds, k=num_clusters)\n",
    "dbscan_labels, dbscan_model = cluster_dbscan(all_embeds, eps=0.5, min_samples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c31d59bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans silhouette score: 0.08680424300224751\n",
      "GMM silhouette score: 0.08680424300224751\n",
      "Agglomerative silhouette score: 0.0888465861950367\n",
      "DBSCAN silhouette score: 0.09936613767276346\n",
      "Spectral silhouette score: 0.0949823892819439\n"
     ]
    }
   ],
   "source": [
    "print(\"KMeans silhouette score:\", cluster_quality(all_embeds, kmeans_labels))\n",
    "print(\"GMM silhouette score:\", cluster_quality(all_embeds, gmm_labels))\n",
    "print(\"Agglomerative silhouette score:\", cluster_quality(all_embeds, agg_labels))\n",
    "print(\"DBSCAN silhouette score:\", cluster_quality(all_embeds, dbscan_labels))\n",
    "print(\"Spectral silhouette score:\", cluster_quality(all_embeds, spec_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c3358a",
   "metadata": {},
   "source": [
    "Hmmm these scores are all very low.. Clusters are not well-separated in the embedding space. DBSCAN highest score... so desnity-based clustering better than kmeans? Kmeans and GMM identical so embeddings are all gaussian. agglomerative and spectral only slightly better. but Spectral does have the second highest so maybe there is some more organic cluster shapes eg swirls/moons. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
